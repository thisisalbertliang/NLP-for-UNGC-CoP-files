import pandas as pd
from ast import literal_eval
import numpy as np
import re
from math import log
from collections import OrderedDict
import nltk
import html
import unicodedata
from textblob import TextBlob
import gensim
import nltk
from collections import Counter

df_cop = pd.read_csv(r'PLEASE INSERT THE PATH TO THE CSV FILE GENERATED BY PHASE_1_TEXTRACT')

#use to clean textracted text from PHASE 1
def clean_text(text):
    cidcompile1 = re.compile(
        r'\(*\s*\(*\s*[cC]\s*i\s*\)*\s*d\s*\:*\s*\:*(?:\(*\s*[cC]\s*i\s*d\s*\:*)?\:*\s*[0-9]+\s*[0-9]{0,}\s*\)*\s*\)*')
    cidcompile2 = re.compile(r'\(\s*[cC]\s*i\s*\)*\s*d\s*\:')
    cidcompile3 = re.compile(r'\:\s*[0-9]+\s*\)')

    t_str = re.sub(cidcompile1, ' ', text)
    t_str = re.sub(cidcompile2, ' ', t_str)
    t_str = re.sub(cidcompile3, ' ', t_str)

    control = re.compile(
        '\x00|\x01|\x02|\x03|\x04|\x05|\x06|\x07|\x08|\x09|\x0a|\x0b|\x0c|\x0d|\x0e|\x0f|\x10|\x11|\x12|\x13|\x14|\x15|\x16|\x17|\x18|\x19|\x1a|\x1b|\x1c|\x1d|\x1e|\x1f|\x7f|\xc2\x80|\xc2\x81|\xc2\x82|\xc2\x83|\xc2\x84|\xc2\x85|\xc2\x86|\xc2\x87|\xc2\x88|\xc2\x89|\xc2\x8a|\xc2\x8b|\xc2\x8c|\xc2\x8d|\xc2\x8e|\xc2\x8f|\xc2\x90|\xc2\x91|\xc2\x92|\xc2\x93|\xc2\x94|\xc2\x95|\xc2\x96|\xc2\x97|\xc2\x98|\xc2\x99|\xc2\x9a|\xc2\x9b|\xc2\x9c|\xc2\x9d|\xc2\x9e|\xc2\x9f')

    t_str = re.sub(control, ' ', t_str)
    t_str = unicodedata.normalize("NFKD", t_str)
    t_str = re.sub('[\uE000-\uF8B6\uF8C1-\uF8E4]+', ' ', t_str)
    t_str = html.unescape(t_str)
    return t_str

def get_subcat(keyword):
    subcat_list = []
    for subcat, kw_list in dict_cat_kw.items():
        if keyword in kw_list:
            subcat_list.append(subcat)
    return subcat_list

#Cleaning the dataframe
df_cop['text'] = df_cop['text'].apply(clean_text)
df_cop['translation'] = df_cop['translation'].apply(clean_text)
df_cop.drop(labels=['Unnamed: 0'], inplace=True, axis=1)

#Downloading and cleaning the taxonomy dataframe
df_kw = pd.read_excel('PLEASE INSERT THE PATH TO YOUR TAXONOMY EXCEL FILE')
df_kw.dropna(how='all', inplace=True)
df_kw['Unnamed: 1'][1:4] = 'Environment'
df_kw['Unnamed: 1'][5:15] = 'Society'
df_kw['Unnamed: 1'][16:23] = 'Economy'
df_kw.drop(54, inplace=True)
df_kw.rename(columns={"Unnamed: 1": "Topic", "Unnamed: 2": "Sub_Category"}, inplace=True)
df_kw.set_index(['Sub_Category'], inplace=True)
df_kw.drop(columns=['Unnamed: {}'.format(i) for i in range(4, 15)], inplace=True)
df_kw.drop(columns=['Unnamed: 0'], inplace=True)
df_kw.rename(columns={"Unnamed: 3": "Key_Words"}, inplace=True)
df_kw.dropna(inplace=True)
#Drop topic column
df_kw.drop(columns='Topic', inplace=True)
df_kw['Key_Words'] = df_kw['Key_Words'].apply(lambda x: x.split(", "))

#Creating a dictionary with subcategory keys and keyword values
dict_cat_kw = {sub_category: keyword for (sub_category, keyword) in zip(df_kw.index.tolist(), sum(df_kw.values.tolist(), []))}
dict_cat_kw['Climate'] = dict_cat_kw.pop('Climate ')
dict_cat_kw['Water'][dict_cat_kw['Water'].index('ocean,')] = 'ocean'
dict_cat_kw['Forced Labour'][dict_cat_kw['Forced Labour'].index(' involuntary labor')] = 'involuntary labor'
dict_cat_kw['Forced Labour'][dict_cat_kw['Forced Labour'].index('involuntary labour,')] = 'involuntary labour'
dict_cat_kw['Anti-Corruption'][dict_cat_kw['Anti-Corruption'].index('extortion,')] = 'extortion'
dict_cat_kw['Corp. Sustainability Management'][dict_cat_kw['Corp. Sustainability Management'].index('business strategy ')] = 'business strategy'
for cat in dict_cat_kw.keys():
    dict_cat_kw[cat] = [kw.lower() for kw in list(filter(lambda kw: kw != '', dict_cat_kw[cat]))]

df_cop['text'] = df_cop['text'].apply(lambda x: x.lower())
df_cop['translation'] = df_cop['translation'].apply(lambda x: x.lower())

kws_all = sum(dict_cat_kw.values(), [])
kws_one = [kw for kw in kws_all if len(kw.split()) == 1]
kws_multi = [kw for kw in kws_all if len(kw.split()) > 1]
corp_id_list = df_cop['corp_id'].tolist()

#Extracting and counting keywords
for index, row in df_cop.iterrows():
    txt = ''
    if row['translation'] == 'already in english':
        txt = row['text']
    else:
        txt = row['translation']
    tb = TextBlob(txt)
    word_freq = tb.word_counts
    kw_freq = {kw: word_freq[kw] for kw in kws_one if kw in set(word_freq)}
    for kw in kws_multi:
        freq = txt.count(kw)
        if  freq > 0:
            kw_freq[kw] = freq
    df_cop.loc[index, 'Keyword_Frequency'] = [kw_freq]
    subcat_freq_dict = {subcat: 0 for subcat in dict_cat_kw.keys()}
    for kw, freq in kw_freq.items():
        kw_subcat_list = get_subcat(kw)
        for subcat in kw_subcat_list:
            subcat_freq_dict[subcat] = subcat_freq_dict[subcat] + freq
    df_cop.loc[index, 'Subcategory_Frequency'] = [subcat_freq_dict]

#Performing sentiment analysis
senti_analy_dict = {}
for index, row in df_cop.iterrows():
    content = ''
    if row['translation'] == "already in english":
        content = row['text'].lower()
    else:
        content = row['translation'].lower()
    corp_id = row['corp_id']
    sentence_list = nltk.sent_tokenize(content)
    content_dict = {}
    for sentence in sentence_list:
        word_list = nltk.word_tokenize(sentence)
        word_freq_dict = dict(nltk.FreqDist(word_list))
        words = [word for word in word_freq_dict.keys()]
        for word in words:
            if word not in kws_one:
                del word_freq_dict[word]
        kw_freq_dict = word_freq_dict
        for kw in kws_multi:
            count = sentence.count(kw)
            if count > 0:
                kw_freq_dict[kw] = count
        sentence_sentiment = TextBlob(sentence).sentiment.polarity
        subcat_sentiment_dict = {subcat: 0 for subcat in dict_cat_kw.keys()}
        for kw, freq in kw_freq_dict.items():
            subcat_list = get_subcat(kw)
            for subcat in subcat_list:
                subcat_sentiment_dict[subcat] += (freq * sentence_sentiment)
        content_dict[sentence] = subcat_sentiment_dict
    content_subcat_senti_dict = {subcat: 0 for subcat in dict_cat_kw.keys()}
    for sentence, subcat_senti_dict in content_dict.items():
        for subcat in subcat_senti_dict.keys():
            content_subcat_senti_dict[subcat] += subcat_senti_dict[subcat]
    senti_analy_dict[corp_id] = content_subcat_senti_dict

df_result.to_csv(r'PLEASE INSERT THE PATH TO YOUR OUTPUT FOLDER')